{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "therapeutic-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "special-survival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Churn Modeling.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "industrial-surrey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RowNumber          False\n",
       " CustomerId         False\n",
       " Surname            False\n",
       " CreditScore        False\n",
       " Geography          False\n",
       " Gender             False\n",
       " Age                False\n",
       " Tenure             False\n",
       " Balance            False\n",
       " NumOfProducts      False\n",
       " HasCrCard          False\n",
       " IsActiveMember     False\n",
       " EstimatedSalary    False\n",
       " Exited             False\n",
       " dtype: bool]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[df.isna().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sophisticated-validation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Inputs=df.drop(['RowNumber','CustomerId','Surname'],axis=1)\n",
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "certain-permit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Female' 'Male']\n",
      "['France' 'Germany' 'Spain']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "Inputs['sex']=le.fit_transform(Inputs['Gender'])\n",
    "print((le.classes_))\n",
    "Inputs['location']=le.fit_transform(Inputs['Geography'])\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "roman-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=Inputs.drop(['Gender','Geography','Exited'],axis=1)\n",
    "Y=Inputs['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "loved-wrapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "narrative-thunder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model=RandomForestClassifier()\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "informed-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "committed-salmon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8585"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "novel-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X_train, Y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "steady-intervention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8575  0.85625 0.85875 0.87375 0.875   0.86875 0.84625 0.84625 0.85625\n",
      " 0.86625 0.875   0.8525  0.84625 0.85    0.86    0.865   0.85625 0.85375\n",
      " 0.87125 0.8675  0.8675  0.87375 0.85125 0.84125 0.8625  0.86    0.84625\n",
      " 0.87    0.845   0.8575 ]\n"
     ]
    }
   ],
   "source": [
    "print(n_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "confident-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test,pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "authorized-commerce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cm,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "lovely-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Softmax, Dense,SimpleRNN,Flatten,RNN,MaxPool2D,ReLU,Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "minor-louisiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "purple-conversion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 372\n",
      "Trainable params: 372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier=Sequential([\n",
    "    Dense(10,input_shape=(10,),activation='relu'),Flatten(),\n",
    "    Dense(20,activation='relu'),\n",
    "    Dense(2,activation='softmax')\n",
    "])\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "neutral-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=Sequential()\n",
    "model1.add(Dense(10,activation='relu'))\n",
    "model1.add(Dense(5,activation='relu'))\n",
    "model1.add(Dense(2,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "danish-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "incident-arthur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "400/400 [==============================] - 3s 3ms/step - loss: 0.4904 - accuracy: 0.7886 - val_loss: 0.4426 - val_accuracy: 0.8030\n",
      "Epoch 2/100\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.4250 - accuracy: 0.8110 - val_loss: 0.4169 - val_accuracy: 0.8165\n",
      "Epoch 3/100\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3955 - accuracy: 0.8336 - val_loss: 0.3927 - val_accuracy: 0.8265\n",
      "Epoch 4/100\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3720 - accuracy: 0.8451 - val_loss: 0.3793 - val_accuracy: 0.8375\n",
      "Epoch 5/100\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3582 - accuracy: 0.8516 - val_loss: 0.3684 - val_accuracy: 0.8390\n",
      "Epoch 6/100\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3510 - accuracy: 0.8551 - val_loss: 0.3618 - val_accuracy: 0.8415\n",
      "Epoch 7/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3461 - accuracy: 0.8560 - val_loss: 0.3616 - val_accuracy: 0.8445\n",
      "Epoch 8/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3432 - accuracy: 0.8595 - val_loss: 0.3575 - val_accuracy: 0.8400\n",
      "Epoch 9/100\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3412 - accuracy: 0.8599 - val_loss: 0.3574 - val_accuracy: 0.8420\n",
      "Epoch 10/100\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3392 - accuracy: 0.8596 - val_loss: 0.3557 - val_accuracy: 0.8420\n",
      "Epoch 11/100\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3390 - accuracy: 0.8574 - val_loss: 0.3540 - val_accuracy: 0.8470\n",
      "Epoch 12/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3372 - accuracy: 0.8605 - val_loss: 0.3527 - val_accuracy: 0.8475\n",
      "Epoch 13/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8586 - val_loss: 0.3518 - val_accuracy: 0.8500\n",
      "Epoch 14/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8608 - val_loss: 0.3512 - val_accuracy: 0.8530\n",
      "Epoch 15/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8620 - val_loss: 0.3495 - val_accuracy: 0.8535\n",
      "Epoch 16/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8636 - val_loss: 0.3509 - val_accuracy: 0.8500\n",
      "Epoch 17/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8618 - val_loss: 0.3505 - val_accuracy: 0.8530\n",
      "Epoch 18/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8634 - val_loss: 0.3497 - val_accuracy: 0.8515\n",
      "Epoch 19/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8621 - val_loss: 0.3491 - val_accuracy: 0.8550\n",
      "Epoch 20/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8633 - val_loss: 0.3523 - val_accuracy: 0.8470\n",
      "Epoch 21/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8630 - val_loss: 0.3480 - val_accuracy: 0.8535\n",
      "Epoch 22/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8644 - val_loss: 0.3464 - val_accuracy: 0.8505\n",
      "Epoch 23/100\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3291 - accuracy: 0.8646 - val_loss: 0.3502 - val_accuracy: 0.8510\n",
      "Epoch 24/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8651 - val_loss: 0.3473 - val_accuracy: 0.8580\n",
      "Epoch 25/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8631 - val_loss: 0.3483 - val_accuracy: 0.8515\n",
      "Epoch 26/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8652 - val_loss: 0.3470 - val_accuracy: 0.8560\n",
      "Epoch 27/100\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3273 - accuracy: 0.8646 - val_loss: 0.3454 - val_accuracy: 0.8565\n",
      "Epoch 28/100\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3278 - accuracy: 0.8644 - val_loss: 0.3463 - val_accuracy: 0.8550\n",
      "Epoch 29/100\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3264 - accuracy: 0.8662 - val_loss: 0.3478 - val_accuracy: 0.8600\n",
      "Epoch 30/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3252 - accuracy: 0.8644 - val_loss: 0.3488 - val_accuracy: 0.8495\n",
      "Epoch 31/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3258 - accuracy: 0.8660 - val_loss: 0.3453 - val_accuracy: 0.8565\n",
      "Epoch 32/100\n",
      "400/400 [==============================] - 0s 969us/step - loss: 0.3255 - accuracy: 0.8641 - val_loss: 0.3483 - val_accuracy: 0.8545\n",
      "Epoch 33/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3251 - accuracy: 0.8650 - val_loss: 0.3467 - val_accuracy: 0.8565\n",
      "Epoch 34/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3249 - accuracy: 0.8649 - val_loss: 0.3474 - val_accuracy: 0.8560\n",
      "Epoch 35/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3244 - accuracy: 0.8631 - val_loss: 0.3487 - val_accuracy: 0.8605\n",
      "Epoch 36/100\n",
      "400/400 [==============================] - 0s 996us/step - loss: 0.3243 - accuracy: 0.8661 - val_loss: 0.3479 - val_accuracy: 0.8530\n",
      "Epoch 37/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3235 - accuracy: 0.8637 - val_loss: 0.3463 - val_accuracy: 0.8555\n",
      "Epoch 38/100\n",
      "400/400 [==============================] - 0s 974us/step - loss: 0.3233 - accuracy: 0.8655 - val_loss: 0.3457 - val_accuracy: 0.8565\n",
      "Epoch 39/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3229 - accuracy: 0.8656 - val_loss: 0.3468 - val_accuracy: 0.8565\n",
      "Epoch 40/100\n",
      "400/400 [==============================] - 0s 972us/step - loss: 0.3237 - accuracy: 0.8660 - val_loss: 0.3465 - val_accuracy: 0.8565\n",
      "Epoch 41/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3219 - accuracy: 0.8665 - val_loss: 0.3502 - val_accuracy: 0.8550\n",
      "Epoch 42/100\n",
      "400/400 [==============================] - 0s 991us/step - loss: 0.3226 - accuracy: 0.8668 - val_loss: 0.3458 - val_accuracy: 0.8575\n",
      "Epoch 43/100\n",
      "400/400 [==============================] - 0s 975us/step - loss: 0.3230 - accuracy: 0.8666 - val_loss: 0.3462 - val_accuracy: 0.8560\n",
      "Epoch 44/100\n",
      "400/400 [==============================] - 0s 946us/step - loss: 0.3222 - accuracy: 0.8691 - val_loss: 0.3467 - val_accuracy: 0.8550\n",
      "Epoch 45/100\n",
      "400/400 [==============================] - 0s 974us/step - loss: 0.3222 - accuracy: 0.8655 - val_loss: 0.3460 - val_accuracy: 0.8580\n",
      "Epoch 46/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3206 - accuracy: 0.8675 - val_loss: 0.3455 - val_accuracy: 0.8550\n",
      "Epoch 47/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3219 - accuracy: 0.8674 - val_loss: 0.3464 - val_accuracy: 0.8570\n",
      "Epoch 48/100\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.3209 - accuracy: 0.8643 - val_loss: 0.3460 - val_accuracy: 0.8560\n",
      "Epoch 49/100\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3213 - accuracy: 0.8673 - val_loss: 0.3483 - val_accuracy: 0.8545\n",
      "Epoch 50/100\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.3215 - accuracy: 0.8671 - val_loss: 0.3458 - val_accuracy: 0.8575\n",
      "Epoch 51/100\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3207 - accuracy: 0.8673 - val_loss: 0.3482 - val_accuracy: 0.8530\n",
      "Epoch 52/100\n",
      "400/400 [==============================] - 0s 970us/step - loss: 0.3207 - accuracy: 0.8662 - val_loss: 0.3489 - val_accuracy: 0.8530\n",
      "Epoch 53/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3212 - accuracy: 0.8677 - val_loss: 0.3490 - val_accuracy: 0.8595\n",
      "Epoch 54/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3199 - accuracy: 0.8683 - val_loss: 0.3474 - val_accuracy: 0.8590\n",
      "Epoch 55/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3197 - accuracy: 0.8664 - val_loss: 0.3451 - val_accuracy: 0.8615\n",
      "Epoch 56/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3200 - accuracy: 0.8706 - val_loss: 0.3458 - val_accuracy: 0.8560\n",
      "Epoch 57/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3197 - accuracy: 0.8674 - val_loss: 0.3453 - val_accuracy: 0.8590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3193 - accuracy: 0.8674 - val_loss: 0.3480 - val_accuracy: 0.8585\n",
      "Epoch 59/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3194 - accuracy: 0.8686 - val_loss: 0.3454 - val_accuracy: 0.8595\n",
      "Epoch 60/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3195 - accuracy: 0.8690 - val_loss: 0.3486 - val_accuracy: 0.8640\n",
      "Epoch 61/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3190 - accuracy: 0.8674 - val_loss: 0.3465 - val_accuracy: 0.8585\n",
      "Epoch 62/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3188 - accuracy: 0.8683 - val_loss: 0.3482 - val_accuracy: 0.8560\n",
      "Epoch 63/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3192 - accuracy: 0.8669 - val_loss: 0.3493 - val_accuracy: 0.8590\n",
      "Epoch 64/100\n",
      "400/400 [==============================] - 0s 1000us/step - loss: 0.3190 - accuracy: 0.8689 - val_loss: 0.3476 - val_accuracy: 0.8560\n",
      "Epoch 65/100\n",
      "400/400 [==============================] - 0s 969us/step - loss: 0.3186 - accuracy: 0.8719 - val_loss: 0.3461 - val_accuracy: 0.8570\n",
      "Epoch 66/100\n",
      "400/400 [==============================] - 0s 993us/step - loss: 0.3186 - accuracy: 0.8708 - val_loss: 0.3488 - val_accuracy: 0.8620\n",
      "Epoch 67/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3181 - accuracy: 0.8679 - val_loss: 0.3480 - val_accuracy: 0.8555\n",
      "Epoch 68/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3189 - accuracy: 0.8691 - val_loss: 0.3462 - val_accuracy: 0.8575\n",
      "Epoch 69/100\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3183 - accuracy: 0.8694 - val_loss: 0.3459 - val_accuracy: 0.8605\n",
      "Epoch 70/100\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3176 - accuracy: 0.8691 - val_loss: 0.3482 - val_accuracy: 0.8595\n",
      "Epoch 71/100\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3175 - accuracy: 0.8680 - val_loss: 0.3496 - val_accuracy: 0.8540\n",
      "Epoch 72/100\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3177 - accuracy: 0.8677 - val_loss: 0.3470 - val_accuracy: 0.8630\n",
      "Epoch 73/100\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3169 - accuracy: 0.8709 - val_loss: 0.3479 - val_accuracy: 0.8605\n",
      "Epoch 74/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3177 - accuracy: 0.8689 - val_loss: 0.3473 - val_accuracy: 0.8615\n",
      "Epoch 75/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3181 - accuracy: 0.8691 - val_loss: 0.3460 - val_accuracy: 0.8600\n",
      "Epoch 76/100\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3176 - accuracy: 0.8702 - val_loss: 0.3482 - val_accuracy: 0.8615\n",
      "Epoch 77/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3174 - accuracy: 0.8666 - val_loss: 0.3473 - val_accuracy: 0.8625\n",
      "Epoch 78/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3170 - accuracy: 0.8712 - val_loss: 0.3482 - val_accuracy: 0.8600\n",
      "Epoch 79/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3172 - accuracy: 0.8695 - val_loss: 0.3474 - val_accuracy: 0.8585\n",
      "Epoch 80/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3173 - accuracy: 0.8689 - val_loss: 0.3462 - val_accuracy: 0.8615\n",
      "Epoch 81/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3170 - accuracy: 0.8710 - val_loss: 0.3463 - val_accuracy: 0.8620\n",
      "Epoch 82/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3172 - accuracy: 0.8683 - val_loss: 0.3502 - val_accuracy: 0.8560\n",
      "Epoch 83/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3169 - accuracy: 0.8696 - val_loss: 0.3471 - val_accuracy: 0.8590\n",
      "Epoch 84/100\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3170 - accuracy: 0.8691 - val_loss: 0.3473 - val_accuracy: 0.8615\n",
      "Epoch 85/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3163 - accuracy: 0.8706 - val_loss: 0.3494 - val_accuracy: 0.8555\n",
      "Epoch 86/100\n",
      "400/400 [==============================] - 0s 996us/step - loss: 0.3172 - accuracy: 0.8712 - val_loss: 0.3486 - val_accuracy: 0.8595\n",
      "Epoch 87/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.8677 - val_loss: 0.3509 - val_accuracy: 0.8630\n",
      "Epoch 88/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.8708 - val_loss: 0.3519 - val_accuracy: 0.8600\n",
      "Epoch 89/100\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3160 - accuracy: 0.8712 - val_loss: 0.3462 - val_accuracy: 0.8600\n",
      "Epoch 90/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3165 - accuracy: 0.8710 - val_loss: 0.3478 - val_accuracy: 0.8565\n",
      "Epoch 91/100\n",
      "400/400 [==============================] - 0s 989us/step - loss: 0.3159 - accuracy: 0.8710 - val_loss: 0.3511 - val_accuracy: 0.8605\n",
      "Epoch 92/100\n",
      "400/400 [==============================] - 0s 971us/step - loss: 0.3162 - accuracy: 0.8683 - val_loss: 0.3492 - val_accuracy: 0.8620\n",
      "Epoch 93/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3160 - accuracy: 0.8687 - val_loss: 0.3473 - val_accuracy: 0.8600\n",
      "Epoch 94/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3159 - accuracy: 0.8692 - val_loss: 0.3530 - val_accuracy: 0.8595\n",
      "Epoch 95/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3153 - accuracy: 0.8702 - val_loss: 0.3506 - val_accuracy: 0.8555\n",
      "Epoch 96/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3170 - accuracy: 0.8698 - val_loss: 0.3513 - val_accuracy: 0.8570\n",
      "Epoch 97/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3159 - accuracy: 0.8700 - val_loss: 0.3496 - val_accuracy: 0.8605\n",
      "Epoch 98/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3154 - accuracy: 0.8696 - val_loss: 0.3500 - val_accuracy: 0.8515\n",
      "Epoch 99/100\n",
      "400/400 [==============================] - 0s 949us/step - loss: 0.3162 - accuracy: 0.8698 - val_loss: 0.3534 - val_accuracy: 0.8535\n",
      "Epoch 100/100\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3156 - accuracy: 0.8710 - val_loss: 0.3495 - val_accuracy: 0.8595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2172e9cd6d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,Y_train,validation_data=(X_test,Y_test),epochs=100,batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-julian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
